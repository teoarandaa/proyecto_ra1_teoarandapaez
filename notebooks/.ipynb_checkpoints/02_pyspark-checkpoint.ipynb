{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6692ccfb",
   "metadata": {},
   "source": [
    "# ETL: Limpieza de Datos de Viviendas en Barcelona (PySpark)\n",
    "\n",
    "## Importamos las librerías necesarias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308567e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import re\n",
    "\n",
    "# Crear SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ETL_Housing_Barcelona\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"✅ SparkSession creada correctamente\")\n",
    "print(f\"Versión de Spark: {spark.version}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd61fccc",
   "metadata": {},
   "source": [
    "## EXTRACT: Cargar los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961281fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el CSV\n",
    "df_raw = spark.read.csv(\n",
    "    \"../data/housing-barcelona.csv\",\n",
    "    header=True,\n",
    "    inferSchema=False  # Leer todo como string primero\n",
    ")\n",
    "\n",
    "print(\"✅ El dataframe se ha creado correctamente\")\n",
    "print(f\"Filas: {df_raw.count()}\")\n",
    "print(f\"Columnas: {len(df_raw.columns)}\")\n",
    "print(f\"\\nColumnas: {df_raw.columns}\")\n",
    "print(f\"\\nPrimeras filas:\")\n",
    "df_raw.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6219bdbd",
   "metadata": {},
   "source": [
    "## TRANSFORM: Limpieza de Datos\n",
    "\n",
    "### Paso 1: Crear copia para trabajar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa981883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear copia del dataframe (en PySpark, los DataFrames son inmutables, así que trabajamos directamente)\n",
    "df_clean = df_raw\n",
    "print(f\"✅ Dataframe listo para trabajar. Filas: {df_clean.count()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a025561",
   "metadata": {},
   "source": [
    "### Paso 2: Eliminar espacios (strip) en columnas de texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1786c2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar trim() a todas las columnas (elimina espacios al inicio y final)\n",
    "for col in df_clean.columns:\n",
    "    df_clean = df_clean.withColumn(col, trim(col(col)))\n",
    "\n",
    "print(\"✅ Espacios eliminados de todas las columnas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfdee46",
   "metadata": {},
   "source": [
    "### Paso 3: Reemplazar valores vacíos por NULL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35382f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar valores que representan \"vacío\" por NULL (None en PySpark)\n",
    "valores_vacios = ['', ' ', 'nan', 'None', 'N/A', 'n/a', 'NULL', 'null', '?', 'unknown']\n",
    "\n",
    "for col in df_clean.columns:\n",
    "    df_clean = df_clean.withColumn(\n",
    "        col,\n",
    "        when(col(col).isin(valores_vacios) | col(col).isNull(), None)\n",
    "        .otherwise(col(col))\n",
    "    )\n",
    "\n",
    "print(\"✅ Valores vacíos convertidos a NULL\")\n",
    "print(f\"\\nValores NULL por columna:\")\n",
    "null_counts = {}\n",
    "for col in df_clean.columns:\n",
    "    null_count = df_clean.filter(col(col).isNull()).count()\n",
    "    if null_count > 0:\n",
    "        null_counts[col] = null_count\n",
    "\n",
    "for col, count in sorted(null_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {col}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95910e0",
   "metadata": {},
   "source": [
    "### Paso 4: Convertir tipos de datos adecuados\n",
    "\n",
    "Primero definimos UDFs (User Defined Functions) para las funciones personalizadas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4ee387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir UDFs para extraer números y convertir texto\n",
    "\n",
    "# UDF para extraer números de strings\n",
    "def extract_number_udf(value):\n",
    "    \"\"\"Extrae el primer número de un string\"\"\"\n",
    "    if value is None:\n",
    "        return None\n",
    "    value_str = str(value)\n",
    "    numbers = re.findall(r'\\d+\\.?\\d*', value_str)\n",
    "    if numbers:\n",
    "        return float(numbers[0])\n",
    "    return None\n",
    "\n",
    "# UDF para convertir texto a número\n",
    "def text_to_number_udf(value):\n",
    "    \"\"\"Convierte texto a número\"\"\"\n",
    "    if value is None:\n",
    "        return None\n",
    "    value_str = str(value).lower().strip()\n",
    "    \n",
    "    text_map = {\n",
    "        'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5,\n",
    "        'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10\n",
    "    }\n",
    "    \n",
    "    if value_str in text_map:\n",
    "        return text_map[value_str]\n",
    "    \n",
    "    if '+' in value_str:\n",
    "        nums = re.findall(r'\\d+', value_str)\n",
    "        if nums:\n",
    "            return int(nums[0])\n",
    "    \n",
    "    numbers = re.findall(r'\\d+\\.?\\d*', value_str)\n",
    "    if numbers:\n",
    "        return float(numbers[0])\n",
    "    return None\n",
    "\n",
    "# UDF para extraer precio\n",
    "def extract_price_udf(value):\n",
    "    \"\"\"Extrae precio numérico\"\"\"\n",
    "    if value is None:\n",
    "        return None\n",
    "    value_str = str(value).replace('€', '').replace('.', '').replace(',', '.').strip()\n",
    "    numbers = re.findall(r'\\d+\\.?\\d*', value_str)\n",
    "    if numbers:\n",
    "        return float(numbers[0])\n",
    "    return None\n",
    "\n",
    "# UDF para extraer precio por m²\n",
    "def extract_price_m2_udf(value):\n",
    "    \"\"\"Extrae precio por m²\"\"\"\n",
    "    if value is None:\n",
    "        return None\n",
    "    value_str = str(value).replace('€/m2', '').replace('€/m²', '').replace('.', '').replace(',', '.').strip()\n",
    "    numbers = re.findall(r'\\d+\\.?\\d*', value_str)\n",
    "    if numbers:\n",
    "        return float(numbers[0])\n",
    "    return None\n",
    "\n",
    "# Registrar UDFs\n",
    "extract_number = udf(extract_number_udf, DoubleType())\n",
    "text_to_number = udf(text_to_number_udf, DoubleType())\n",
    "extract_price = udf(extract_price_udf, DoubleType())\n",
    "extract_price_m2 = udf(extract_price_m2_udf, DoubleType())\n",
    "\n",
    "print(\"✅ UDFs definidas y registradas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9af2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar columnas numéricas usando las UDFs\n",
    "\n",
    "# Limpiar surface_m2\n",
    "if 'surface_m2' in df_clean.columns:\n",
    "    df_clean = df_clean.withColumn('surface_m2', extract_number('surface_m2'))\n",
    "\n",
    "# Limpiar rooms\n",
    "if 'rooms' in df_clean.columns:\n",
    "    df_clean = df_clean.withColumn('rooms', text_to_number('rooms'))\n",
    "\n",
    "# Limpiar bathrooms\n",
    "if 'bathrooms' in df_clean.columns:\n",
    "    df_clean = df_clean.withColumn('bathrooms', text_to_number('bathrooms'))\n",
    "\n",
    "# Limpiar price_eur\n",
    "if 'price_eur' in df_clean.columns:\n",
    "    df_clean = df_clean.withColumn('price_eur', extract_price('price_eur'))\n",
    "\n",
    "# Limpiar price_per_m2\n",
    "if 'price_per_m2' in df_clean.columns:\n",
    "    df_clean = df_clean.withColumn('price_per_m2', extract_price_m2('price_per_m2'))\n",
    "\n",
    "# Convertir coordenadas a numérico\n",
    "if 'latitude' in df_clean.columns:\n",
    "    df_clean = df_clean.withColumn('latitude', col('latitude').cast('double'))\n",
    "if 'longitude' in df_clean.columns:\n",
    "    df_clean = df_clean.withColumn('longitude', col('longitude').cast('double'))\n",
    "\n",
    "print(\"✅ Columnas numéricas limpiadas y convertidas\")\n",
    "print(f\"\\nTipos de datos numéricos:\")\n",
    "df_clean.select('surface_m2', 'rooms', 'bathrooms', 'price_eur', 'price_per_m2', 'latitude', 'longitude').printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff669aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir columnas que deben ser enteros\n",
    "if 'rooms' in df_clean.columns:\n",
    "    df_clean = df_clean.withColumn('rooms', col('rooms').cast('int'))\n",
    "if 'bathrooms' in df_clean.columns:\n",
    "    df_clean = df_clean.withColumn('bathrooms', col('bathrooms').cast('int'))\n",
    "\n",
    "print(\"✅ Columnas convertidas a enteros\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e465fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar que las columnas de texto sean string\n",
    "text_cols = ['listing_id', 'operation', 'district', 'neighborhood', 'address', \n",
    "             'floor', 'condition', 'energy_certificate', 'agency']\n",
    "\n",
    "for col_name in text_cols:\n",
    "    if col_name in df_clean.columns:\n",
    "        df_clean = df_clean.withColumn(\n",
    "            col_name,\n",
    "            when(col(col_name).isNull() | (col(col_name) == 'nan'), None)\n",
    "            .otherwise(col(col_name).cast('string'))\n",
    "        )\n",
    "\n",
    "print(\"✅ Columnas de texto convertidas a string\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a475f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir columnas booleanas\n",
    "boolean_cols = ['elevator', 'balcony', 'furnished', 'has_parking']\n",
    "\n",
    "for col_name in boolean_cols:\n",
    "    if col_name in df_clean.columns:\n",
    "        df_clean = df_clean.withColumn(\n",
    "            col_name,\n",
    "            when(lower(trim(col(col_name))).isin(['y', 'yes', 'sí', 'si', 's', '1', 'true']), True)\n",
    "            .when(lower(trim(col(col_name))).isin(['n', 'no', '0', 'false']), False)\n",
    "            .otherwise(None)\n",
    "        )\n",
    "\n",
    "print(\"✅ Columnas booleanas convertidas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fa0fa6",
   "metadata": {},
   "source": [
    "### Paso 5: Rellenar valores faltantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310ad9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar valores faltantes\n",
    "# Para columnas de texto: rellenar con \"{nombre_columna} empty\"\n",
    "# Para columnas numéricas: rellenar con la media\n",
    "\n",
    "print(\"=== RELLENANDO VALORES FALTANTES ===\\n\")\n",
    "\n",
    "# Obtener esquema para identificar tipos\n",
    "schema = df_clean.schema\n",
    "\n",
    "# Crear diccionario para fillna\n",
    "fill_dict = {}\n",
    "\n",
    "# Rellenar columnas de texto (StringType)\n",
    "for field in schema.fields:\n",
    "    if isinstance(field.dataType, StringType):\n",
    "        fill_dict[field.name] = f\"{field.name} empty\"\n",
    "        print(f\"✅ {field.name}: valores rellenados con '{fill_dict[field.name]}'\")\n",
    "\n",
    "# Rellenar columnas numéricas con la media\n",
    "numeric_cols = ['surface_m2', 'rooms', 'bathrooms', 'price_eur', 'price_per_m2', 'latitude', 'longitude']\n",
    "\n",
    "for col_name in numeric_cols:\n",
    "    if col_name in df_clean.columns:\n",
    "        # Calcular media\n",
    "        mean_value = df_clean.agg(avg(col(col_name)).alias('mean')).collect()[0]['mean']\n",
    "        \n",
    "        if mean_value is not None:\n",
    "            # Si es int, redondear\n",
    "            if col_name in ['rooms', 'bathrooms']:\n",
    "                mean_value = int(round(mean_value))\n",
    "                fill_dict[col_name] = mean_value\n",
    "                print(f\"✅ {col_name}: valores rellenados con media = {mean_value} (entero)\")\n",
    "            else:\n",
    "                fill_dict[col_name] = mean_value\n",
    "                print(f\"✅ {col_name}: valores rellenados con media = {mean_value:.2f}\")\n",
    "\n",
    "# Aplicar fillna\n",
    "df_clean = df_clean.fillna(fill_dict)\n",
    "\n",
    "# Verificar valores NULL restantes\n",
    "null_count = 0\n",
    "for col_name in df_clean.columns:\n",
    "    col_null_count = df_clean.filter(col(col_name).isNull()).count()\n",
    "    if col_null_count > 0:\n",
    "        null_count += col_null_count\n",
    "\n",
    "print(f\"\\n✅ Todos los valores faltantes han sido rellenados\")\n",
    "print(f\"Valores NULL restantes: {null_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750527f6",
   "metadata": {},
   "source": [
    "### Verificación: Comparación antes/después\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cda248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar ejemplos de limpieza\n",
    "print(\"=== EJEMPLOS DE LIMPIEZA ===\\n\")\n",
    "print(\"ANTES (RAW):\")\n",
    "df_raw.select('surface_m2', 'rooms', 'bathrooms', 'price_eur', 'price_per_m2', 'elevator', 'district').show(10, truncate=False)\n",
    "print(\"\\nDESPUÉS (CLEAN):\")\n",
    "df_clean.select('surface_m2', 'rooms', 'bathrooms', 'price_eur', 'price_per_m2', 'elevator', 'district').show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da654627",
   "metadata": {},
   "source": [
    "### Resumen de la transformación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582ca5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== RESUMEN DE LA TRANSFORMACIÓN ===\\n\")\n",
    "print(f\"Filas: {df_clean.count()}\")\n",
    "print(f\"Columnas: {len(df_clean.columns)}\")\n",
    "print(f\"\\nEsquema del dataset limpio:\")\n",
    "df_clean.printSchema()\n",
    "print(f\"\\nPrimeras filas del dataset limpio:\")\n",
    "df_clean.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cc789e",
   "metadata": {},
   "source": [
    "## LOAD: Guardar datos limpios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a798d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el dataframe limpio\n",
    "output_path = \"../data/housing-barcelona-clean-pyspark.csv\"\n",
    "\n",
    "df_clean.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(output_path)\n",
    "\n",
    "print(f\"✅ Datos limpios guardados en: {output_path}\")\n",
    "print(f\"\\nArchivo guardado exitosamente con {df_clean.count()} filas y {len(df_clean.columns)} columnas\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
